{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem (CLT) - Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Introduction to the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è You can skip this section of the `Recap - Central Limit Theorem - Revisited` if you had time to read it during the `Challenge - The Central Limit Theorem - A first approach`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two convergence theorems revolutionized the disciplines of probability and statistics:**\n",
    "- **`LLN`: the Law of Large Numbers**\n",
    "- **`CLT`: the Central Limit Theorem**\n",
    "\n",
    "üßëüèª‚Äçüè´ What is the CLT? According to [Wikipedia](https://en.wikipedia.org/wiki/Central_limit_theorem)\n",
    "\n",
    "> In probability theory, the central limit theorem (CLT) establishes that, in many situations, when independent random variables are summed up, their properly normalized sum tends towards a `Gaussian/normal distribution` (informally a `bell curve`) even if the original variables themselves are not normally distributed. The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ  Interpreting and Experimenting with the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ  Let's illustrate how to use the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) in a dataset:\n",
    "\n",
    "* Given a population, let's consider a feature (e.g. size, weight, salary, etc.) for each individual.\n",
    "\n",
    "\n",
    "üöÄ  The important takeaway of these two theorems is that **whatever the shape of the distribution** of a given feature over the population, **the distribution of the (sampled) mean<u>S</u> tends to be Gaussian**:\n",
    "* `the mean of the means` = $ \\mu$ (Law of Large Numbers)\n",
    "* `the standard deviation of the means` = $ \\frac{\\sigma}{\\sqrt{n}} $  (Central Limit Theorem)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/IllustrationCentralTheorem.png/400px-IllustrationCentralTheorem.png)\n",
    "\n",
    "üí°  We can wrap it up the following way:\n",
    "\n",
    "$$ \\large \\bar{X} \\approx_{n \\rightarrow \\infty} \\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not convinced?  Play by yourself with this [no-code dataviz tool](https://seeing-theory.brown.edu/probability-distributions/) first! \n",
    " (section CTL)\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/math/ctl_playground.png\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüî¨  Let's verify this experimentally with Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  üöÄ Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ In this challenge, we will use the `tips` dataset from the `seaborn` library to illustrate the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Scientific libraries\n",
    "import scipy.stats as stats\n",
    "# Data Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Load the `tips` dataset from `seaborn` into a `df` variable and display the first rows ‚ùì\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    You can use <a href=\"https://seaborn.pydata.org/generated/seaborn.load_dataset.html\"><code>seaborn.load_dataset()</code></a>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßê Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many rows are available in the dataset ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä Plot the distribution of the `total_bill` column in the restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the [**skewness**](https://whatis.techtarget.com/definition/skewness) value of this distribution ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create two variables `mu` and `sigma` to store the mean and standard deviation of tips, respectively ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≤ Sampling the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Pick randomly - and with replacement - 10 rows of the dataset, and compute the mean $ \\bar{X} $ of this sample.\n",
    "\n",
    "Run this cell a few times.\n",
    "* Do you get the same result each time?\n",
    "* Did you expect it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"total_bill\"].sample(1000, replace=True).mean()\n",
    "df[\"total_bill\"].sample(5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Create a `means` list storing a list of means of $N$ samples (each of them with size $n$).\n",
    "\n",
    "Start with $n = 5$ and $N = 10$\n",
    "\n",
    "üìä In the same cell, **plot** the distribution of `means`. \n",
    "\n",
    "üïµÔ∏è‚Äç‚ôÄÔ∏è Let's play with the *sample size n* and the *number of samples N*:\n",
    "- `sample size`: Keep $N$ constant, `increase n`. What do you observe?\n",
    "    - Plot a grid of 6 distributions playing with  $ n \\in \\{ 1, 5, 50, 100, 500, 1000 \\}$\n",
    "- `number of samples`:Then, keep $n$ constant and `increase N`. What do you observe?\n",
    "    - Plot a grid of 6 distributions playing with  $ N \\in \\{ 10, 20, 30, 50, 100, 500 \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Playing with the `sample size` $n$</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As *n* increases:\n",
    "* the distribution of the means converges towards the theoretical mean $ \\mu $ (LLN)\n",
    "* the variance around $ \\mu $ tends towards 0 (indeed: $ \\large \\frac{\\sigma}{\\sqrt{n}} \\rightarrow_{n \\rightarrow \\infty} 0 $)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Playing with the `number_of_samples` $N$</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers in one sample\n",
    "n = 200\n",
    "\n",
    "# Number of samples\n",
    "list_of_N = [10, 20, 30, 50, 100, 500]\n",
    " \n",
    "# Plot 6 graphs : 2 rows by 3 columns for the 6 values of N\n",
    "fix,axes = plt.subplots(nrows=2,ncols=3,figsize=(15,10))\n",
    "\n",
    "for N, ax in zip(list_of_N,axes.flat):\n",
    "    means = [df[\"total_bill\"].sample(n, replace=True).mean() for i in range(N)]\n",
    "    \n",
    "    ax.set_title(f\"N={N}\")\n",
    "    ax.set_xlim(0, 40)\n",
    "    \n",
    "    sns.histplot(means,bins=10,ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As *N* increases:\n",
    "* the distribution of the means is less noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë©üèª‚Äçüíª Verifying the CLT with Simulations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/IllustrationCentralTheorem.png/400px-IllustrationCentralTheorem.png)\n",
    "\n",
    "$$ \\large \\bar{X} \\approx_{n \\rightarrow \\infty} \\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• Let's verify the Central Limit Theorem computationally \n",
    "\n",
    "For each value of `n`:\n",
    "- Compare `mu` with the mean of means\n",
    "- Compare `sigma` with the standard deviation of the means (don't forget the $\\sqrt n$ adjustment)\n",
    "- Compute the `skewness` of the sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mu: {round(mu,2)}\")\n",
    "print(f\"sigma: {round(sigma,2)}\")\n",
    "print(f\"skewness: {round(skew,2)}\")\n",
    "print(f\"kurtosis: {round(kurtosis,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚≠êÔ∏è Real-life application of the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's consider `n` =  100 rows **sampled from the dataset**. What is the probability that the cumulated total bill is **lower than 1800‚Ç¨**? \n",
    "\n",
    "üöÄ `n > 30` is enough to apply the Central Limit Theorem. The distribution of the sampled means follows a **`Gaussian Distribution`** (already referred to as a **`Normal Distribution`**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "‚ùì Plot the  **`pdf`** (a.k.a. `probability density function`) of the sampled means of the total bills. You can use ***[`scipy.stats.norm`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)***\n",
    "\n",
    "$$ \\large \\bar{X} \\approx_{n \\rightarrow \\infty} \\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ We'll revisit the concept of Gaussian Variable during the lecture `Statistical Inference`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the probability we are looking for? Use the `cdf` method to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compute the z-score for the value `18‚Ç¨`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° This z-score actually confirms the probability we found above. Take a look at the [Standard Normal Table](https://en.wikipedia.org/wiki/Standard_normal_table); if you scroll through the rows and look for -2.00 (our z-score), you will see that it corresponds to **0.02275**, which is approximately the same value we have for our probability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the normal distribution (0, 1) and a red dot for the target (use the `pdf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ And...that's the end of this module for today!\n",
    "\n",
    "üíæ Again, you know the routine: `git add/commit/push`!\n",
    "\n",
    "---\n",
    "\n",
    "üéâ Massive congratulations for making it to the end of the Mathematics module! \n",
    "\n",
    "\n",
    "ü§© If you fell in love with maths, look at the following video: [**`The Map of Mathematics`**](https://www.youtube.com/watch?v=OmJ-4B-mS-Y) (11 min - 9M views on YouTube)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/272/32264483720_c51bdde679_n.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üìÜ So, **how do you prepare yourself to enter the world of `Decision Science` now** ? \n",
    "\n",
    "- üêç **`Python for Data Science`** :\n",
    "    - the more we progress through the bootcamp, the more you will have to be proficient in Python so that you can focus on the new Data Science concepts and not on the programming questions!\n",
    "    - _Example_: think about a professional tennis player ‚Äî before a game, he/she elaborates a strategy with the coach to beat the opponent, not to make a good serve or to do a top spin!\n",
    "    \n",
    "- üî¢ **`SQL`**:\n",
    "    - Mastering database queries is at the heart of _any_ Data Science and Analytics job, even before Python for Data Analysts\n",
    "    - It is fundamental that you master how to _join tables_ with SQL, we will re-use the concepts of _merging tables_ extensively with _Pandas_, and you will have to do it not only during your projects but also afterwards on your next job\n",
    "    \n",
    "- üêº **`Pandas/NumPy`**\n",
    "    - The more of an expert you are at manipulating data with these two libraries, the more you can focus on adding value to your analysis \n",
    "    - The same way Excel masters will outshine their colleagues in Finance, Pandas/NumPy wizards will be much faster in focusing on handling new data\n",
    "    \n",
    "- üßÆ **`Maths`**:\n",
    "    - `Algebra`: you must be comfortable dealing with matrices, DataFrames and NumPy Arrays! We will use them everywhere, even for Computer Vision and Image Preprocessing. We do not ask you to be an expert by taking a full Linear Algebra course like [MIT - Gilbert Strang - Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/) (Open Source course on MIT OpenCourseWare) at university, but at least be proficient in getting and interpreting shapes of matrices, transposing, computing the inverse of a matrix, and matrix multiplication\n",
    "    - `Probability and Statistics`: we will re-use the Gaussian Distribution and the Central Limit Theorem in the next module, so make sure you understood these concepts and write down all the remaining questions you would like to ask your teachers and TAs!\n",
    "\n",
    "üëâ These topics should be your priorities! Later, you can review challenges related to Data Visualization and Data Sourcing ‚Äî for example, if you still have time after reviewing the priorities or before starting your Data Science Projects.\n",
    "\n",
    "\n",
    "üëã See you soon ! üëã\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
